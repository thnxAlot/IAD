{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "killing-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ilyac\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import LRScheduler, BatchScoring, Checkpoint, LoadInitState\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer, classification_report\n",
    "import xgboost as xg\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(precision=3)\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-nurse",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alive-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senior</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Internet</th>\n",
       "      <th>Security</th>\n",
       "      <th>Backup</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Support</th>\n",
       "      <th>TV</th>\n",
       "      <th>Movies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>EBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>54.2</td>\n",
       "      <td>3623.95</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Senior Married Dependents  Tenure Internet Security Backup Insurance  \\\n",
       "Index                                                                        \n",
       "0         No     Yes        Yes      67      DSL      Yes    Yes       Yes   \n",
       "\n",
       "      Support   TV Movies  Contract EBilling            PaymentMethod  \\\n",
       "Index                                                                   \n",
       "0         Yes  Yes     No  Two year       No  Credit card (automatic)   \n",
       "\n",
       "       MonthlyCharges  TotalCharges  Churn  \n",
       "Index                                       \n",
       "0                54.2       3623.95  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "data.TotalCharges = data.TotalCharges.replace(' ', 0).astype(float)\n",
    "data = data.drop(['Gender', 'Phone', 'MultiplePhones'], axis=1)\n",
    "data = data.replace({'Senior': {1: 'Yes', 0: 'No'}})\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-brown",
   "metadata": {},
   "source": [
    "### Split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(data.drop(['Churn'], axis=1), \n",
    "#                                                     data.Churn,\n",
    "#                                                     test_size = 0.4)\n",
    "\n",
    "X_train, Y_train = data.drop(['Churn'], axis=1), data.Churn\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-sequence",
   "metadata": {},
   "source": [
    "### Create a preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "racial-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(), make_column_selector(dtype_include=object))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hundred-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = preprocessor.fit_transform(X_train).astype(np.float32)\n",
    "Y_train = np.array(Y_train).astype(np.int64)\n",
    "# X_test_preprocessed = preprocessor.transform(X_test).astype(np.float32)\n",
    "# Y_test = np.array(Y_test).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-relaxation",
   "metadata": {},
   "source": [
    "### Создаем сеть на торче и используем ее в sklearn через skorch\n",
    "\n",
    "Используем arcface из задачи face recognition, который можно применять для open set classification. По сути, на важно, что он разделяет вектора фичей в пространстве так, чтобы они лежали на гиперсфере и вектора разных классов были как можно дальше друг от друга, в то время как вектора одного и того же класса как можно ближе друг к другу в плане углового расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fluid-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размер вектора фичей на выходе сети\n",
    "#\n",
    "embed_feat_size = 16\n",
    "\n",
    "# L2 normalization layer.\n",
    "#\n",
    "def l2n(x, eps=1e-6):\n",
    "    return x / (torch.norm(x, p=2, dim=1, keepdim=True) + eps).expand_as(x)\n",
    "\n",
    "class L2N(nn.Module):\n",
    "\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(L2N,self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return l2n(x, eps=self.eps)\n",
    "\n",
    "\n",
    "# ArcFace head.\n",
    "#\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implementation of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample (should match number of classes in the training dataset)\n",
    "            s: norm of input feature (hypersphere radius)\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features=embed_feat_size, out_features=2, s=20.0, m=.6, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        \n",
    "        one_hot = torch.zeros(cosine.size(), device='cpu')\n",
    "        \n",
    "        one_hot.scatter_(1, target.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine) \n",
    "        output *= self.s\n",
    "        # print(output)\n",
    "\n",
    "        return self.criterion.forward(output, target)\n",
    "\n",
    "    \n",
    "class ArcFaceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ArcFaceNet, self).__init__()\n",
    "        self.net = MyNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_size=39, embedding_size=embed_feat_size * 2):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.norm = L2N()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, embedding_size)\n",
    "        self.bn1 = nn.BatchNorm1d(embedding_size)\n",
    "        self.relu1 = nn.PReLU(embedding_size)\n",
    "        \n",
    "        self.fc2 = nn.Linear(embedding_size, embedding_size // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(embedding_size // 2)\n",
    "        self.relu2 = nn.PReLU(embedding_size // 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.fc1(x)))\n",
    "        x = self.relu2(self.bn2(self.fc2(x)))\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affiliated-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingNet = ArcFaceNet\n",
    "criterion = ArcMarginProduct\n",
    "\n",
    "cp = Checkpoint(dirname='checkpoints6')\n",
    "load_state = LoadInitState(cp)\n",
    "    \n",
    "net = NeuralNetClassifier(\n",
    "    embeddingNet,\n",
    "    max_epochs=200,\n",
    "    lr=3e-4,\n",
    "    criterion=criterion,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__amsgrad=True,\n",
    "    optimizer__weight_decay=0.25,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[\n",
    "        ('lr_scheduler',\n",
    "         LRScheduler(policy=torch.optim.lr_scheduler.StepLR,\n",
    "                     gamma=0.4,\n",
    "                     step_size=25)),\n",
    "        cp,\n",
    "        load_state,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brutal-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1       \u001b[36m10.8427\u001b[0m       \u001b[32m0.0362\u001b[0m        \u001b[35m9.3915\u001b[0m     +  0.1965\n",
      "      2        \u001b[36m8.3707\u001b[0m       \u001b[32m0.0431\u001b[0m        \u001b[35m7.2482\u001b[0m     +  0.1287\n",
      "      3        \u001b[36m6.9463\u001b[0m       0.0376        \u001b[35m6.3072\u001b[0m     +  0.1227\n",
      "      4        \u001b[36m6.2771\u001b[0m       0.0195        \u001b[35m5.8821\u001b[0m     +  0.1207\n",
      "      5        \u001b[36m5.8681\u001b[0m       0.0153        \u001b[35m5.5223\u001b[0m     +  0.1197\n",
      "      6        \u001b[36m5.5664\u001b[0m       0.0139        \u001b[35m5.2466\u001b[0m     +  0.1227\n",
      "      7        \u001b[36m5.3523\u001b[0m       0.0111        \u001b[35m5.1219\u001b[0m     +  0.1366\n",
      "      8        \u001b[36m5.1523\u001b[0m       0.0056        \u001b[35m4.9066\u001b[0m     +  0.1466\n",
      "      9        \u001b[36m4.9760\u001b[0m       0.0056        \u001b[35m4.8313\u001b[0m     +  0.1217\n",
      "     10        \u001b[36m4.8541\u001b[0m       0.0056        \u001b[35m4.6786\u001b[0m     +  0.1217\n",
      "     11        \u001b[36m4.7085\u001b[0m       0.0042        \u001b[35m4.6033\u001b[0m     +  0.1406\n",
      "     12        \u001b[36m4.5791\u001b[0m       0.0042        \u001b[35m4.4885\u001b[0m     +  0.1356\n",
      "     13        \u001b[36m4.4954\u001b[0m       0.0042        \u001b[35m4.3894\u001b[0m     +  0.1277\n",
      "     14        \u001b[36m4.4181\u001b[0m       0.0042        \u001b[35m4.2760\u001b[0m     +  0.1277\n",
      "     15        \u001b[36m4.2919\u001b[0m       0.0028        \u001b[35m4.2216\u001b[0m     +  0.1566\n",
      "     16        \u001b[36m4.2189\u001b[0m       0.0014        \u001b[35m4.1393\u001b[0m     +  0.1486\n",
      "     17        \u001b[36m4.1860\u001b[0m       0.0014        \u001b[35m4.0839\u001b[0m     +  0.1217\n",
      "     18        \u001b[36m4.1087\u001b[0m       0.0014        \u001b[35m3.9801\u001b[0m     +  0.1496\n",
      "     19        \u001b[36m4.0194\u001b[0m       0.0014        \u001b[35m3.9349\u001b[0m     +  0.1496\n",
      "     20        \u001b[36m3.9846\u001b[0m       0.0014        \u001b[35m3.8867\u001b[0m     +  0.1237\n",
      "     21        \u001b[36m3.9259\u001b[0m       0.0014        \u001b[35m3.8574\u001b[0m     +  0.1207\n",
      "     22        \u001b[36m3.8869\u001b[0m       0.0014        \u001b[35m3.7780\u001b[0m     +  0.1257\n",
      "     23        \u001b[36m3.8395\u001b[0m       0.0014        \u001b[35m3.7549\u001b[0m     +  0.1227\n",
      "     24        \u001b[36m3.7793\u001b[0m       0.0014        \u001b[35m3.7032\u001b[0m     +  0.1247\n",
      "     25        \u001b[36m3.7352\u001b[0m       0.0014        \u001b[35m3.6503\u001b[0m     +  0.1646\n",
      "     26        \u001b[36m3.6942\u001b[0m       0.0014        \u001b[35m3.6353\u001b[0m     +  0.1486\n",
      "     27        \u001b[36m3.6811\u001b[0m       0.0014        3.6396        0.1227\n",
      "     28        \u001b[36m3.6505\u001b[0m       0.0014        \u001b[35m3.6070\u001b[0m     +  0.1227\n",
      "     29        3.6631       0.0014        3.6076        0.1336\n",
      "     30        \u001b[36m3.6314\u001b[0m       0.0014        \u001b[35m3.5857\u001b[0m     +  0.1506\n",
      "     31        3.6497       0.0014        \u001b[35m3.5785\u001b[0m     +  0.1346\n",
      "     32        \u001b[36m3.5970\u001b[0m       0.0014        \u001b[35m3.5569\u001b[0m     +  0.1267\n",
      "     33        3.6060       0.0014        \u001b[35m3.5446\u001b[0m     +  0.1277\n",
      "     34        \u001b[36m3.5697\u001b[0m       0.0014        \u001b[35m3.5168\u001b[0m     +  0.1566\n",
      "     35        \u001b[36m3.5487\u001b[0m       0.0014        \u001b[35m3.5128\u001b[0m     +  0.1416\n",
      "     36        \u001b[36m3.5441\u001b[0m       0.0014        \u001b[35m3.4877\u001b[0m     +  0.1237\n",
      "     37        \u001b[36m3.5315\u001b[0m       0.0014        \u001b[35m3.4750\u001b[0m     +  0.1247\n",
      "     38        3.5389       0.0014        \u001b[35m3.4667\u001b[0m     +  0.1267\n",
      "     39        \u001b[36m3.4773\u001b[0m       0.0014        \u001b[35m3.4522\u001b[0m     +  0.1257\n",
      "     40        \u001b[36m3.4584\u001b[0m       0.0014        3.4529        0.1217\n",
      "     41        3.4732       0.0000        \u001b[35m3.4036\u001b[0m     +  0.1287\n",
      "     42        3.4747       0.0000        \u001b[35m3.3914\u001b[0m     +  0.1247\n",
      "     43        \u001b[36m3.4436\u001b[0m       0.0000        \u001b[35m3.3786\u001b[0m     +  0.1237\n",
      "     44        \u001b[36m3.4241\u001b[0m       0.0000        \u001b[35m3.3784\u001b[0m     +  0.1496\n",
      "     45        \u001b[36m3.4012\u001b[0m       0.0000        \u001b[35m3.3660\u001b[0m     +  0.1426\n",
      "     46        \u001b[36m3.3922\u001b[0m       0.0000        \u001b[35m3.3403\u001b[0m     +  0.1237\n",
      "     47        \u001b[36m3.3812\u001b[0m       0.0000        \u001b[35m3.3040\u001b[0m     +  0.1227\n",
      "     48        \u001b[36m3.3565\u001b[0m       0.0000        3.3145        0.1217\n",
      "     49        \u001b[36m3.3480\u001b[0m       0.0000        3.3107        0.1267\n",
      "     50        3.3829       0.0000        \u001b[35m3.2972\u001b[0m     +  0.1227\n",
      "     51        \u001b[36m3.3092\u001b[0m       0.0000        \u001b[35m3.2890\u001b[0m     +  0.1237\n",
      "     52        3.3458       0.0000        3.2899        0.1217\n",
      "     53        \u001b[36m3.3017\u001b[0m       0.0000        \u001b[35m3.2712\u001b[0m     +  0.1426\n",
      "     54        3.3082       0.0000        \u001b[35m3.2689\u001b[0m     +  0.1436\n",
      "     55        3.3060       0.0000        3.2744        0.1237\n",
      "     56        3.3059       0.0000        \u001b[35m3.2580\u001b[0m     +  0.1247\n",
      "     57        \u001b[36m3.3007\u001b[0m       0.0000        \u001b[35m3.2472\u001b[0m     +  0.1227\n",
      "     58        3.3076       0.0000        \u001b[35m3.2296\u001b[0m     +  0.1227\n",
      "     59        3.3097       0.0000        3.2296        0.1227\n",
      "     60        \u001b[36m3.2771\u001b[0m       0.0000        3.2386        0.1247\n",
      "     61        \u001b[36m3.2658\u001b[0m       0.0000        3.2416        0.1217\n",
      "     62        \u001b[36m3.2581\u001b[0m       0.0000        3.2322        0.1227\n",
      "     63        3.2668       0.0000        \u001b[35m3.2253\u001b[0m     +  0.1247\n",
      "     64        3.2666       0.0000        \u001b[35m3.2115\u001b[0m     +  0.1227\n",
      "     65        \u001b[36m3.2495\u001b[0m       0.0000        \u001b[35m3.2064\u001b[0m     +  0.1257\n",
      "     66        \u001b[36m3.2316\u001b[0m       0.0000        3.2110        0.1207\n",
      "     67        3.2557       0.0000        3.2165        0.1257\n",
      "     68        3.2469       0.0000        \u001b[35m3.2053\u001b[0m     +  0.1646\n",
      "     69        \u001b[36m3.2290\u001b[0m       0.0000        \u001b[35m3.2008\u001b[0m     +  0.1366\n",
      "     70        3.2555       0.0000        \u001b[35m3.1979\u001b[0m     +  0.1356\n",
      "     71        \u001b[36m3.2273\u001b[0m       0.0000        \u001b[35m3.1930\u001b[0m     +  0.1227\n",
      "     72        3.2349       0.0000        3.1949        0.1396\n",
      "     73        \u001b[36m3.2164\u001b[0m       0.0000        \u001b[35m3.1838\u001b[0m     +  0.1456\n",
      "     74        \u001b[36m3.2126\u001b[0m       0.0000        \u001b[35m3.1723\u001b[0m     +  0.1277\n",
      "     75        \u001b[36m3.2016\u001b[0m       0.0000        3.1756        0.1237\n",
      "     76        3.2592       0.0000        3.1788        0.1247\n",
      "     77        3.2120       0.0000        3.1757        0.1247\n",
      "     78        3.2132       0.0000        3.1774        0.1247\n",
      "     79        3.2084       0.0000        3.1864        0.1237\n",
      "     80        \u001b[36m3.1873\u001b[0m       0.0000        3.1753        0.1406\n",
      "     81        3.2175       0.0000        3.1788        0.1496\n",
      "     82        3.2110       0.0000        \u001b[35m3.1719\u001b[0m     +  0.1386\n",
      "     83        3.2241       0.0000        \u001b[35m3.1712\u001b[0m     +  0.1426\n",
      "     84        3.1920       0.0000        3.1754        0.1287\n",
      "     85        3.2059       0.0000        3.1739        0.1247\n",
      "     86        3.2038       0.0000        \u001b[35m3.1649\u001b[0m     +  0.1237\n",
      "     87        3.1968       0.0000        \u001b[35m3.1582\u001b[0m     +  0.1217\n",
      "     88        \u001b[36m3.1869\u001b[0m       0.0000        \u001b[35m3.1513\u001b[0m     +  0.1207\n",
      "     89        \u001b[36m3.1817\u001b[0m       0.0000        3.1619        0.1257\n",
      "     90        3.2253       0.0000        3.1743        0.1217\n",
      "     91        \u001b[36m3.1652\u001b[0m       0.0000        3.1581        0.1227\n",
      "     92        3.2226       0.0000        3.1667        0.1217\n",
      "     93        3.1751       0.0000        3.1651        0.1217\n",
      "     94        3.1799       0.0000        \u001b[35m3.1442\u001b[0m     +  0.1227\n",
      "     95        3.1936       0.0000        3.1591        0.1237\n",
      "     96        3.1678       0.0000        3.1497        0.1217\n",
      "     97        3.2016       0.0000        \u001b[35m3.1397\u001b[0m     +  0.1237\n",
      "     98        \u001b[36m3.1539\u001b[0m       0.0000        \u001b[35m3.1342\u001b[0m     +  0.1227\n",
      "     99        3.2027       0.0000        3.1367        0.1247\n",
      "    100        \u001b[36m3.1512\u001b[0m       0.0000        \u001b[35m3.1322\u001b[0m     +  0.1217\n",
      "    101        3.1621       0.0000        3.1326        0.1247\n",
      "    102        3.1963       0.0000        3.1432        0.1237\n",
      "    103        3.1561       0.0000        3.1415        0.1267\n",
      "    104        3.1642       0.0000        3.1458        0.1915\n",
      "    105        \u001b[36m3.1452\u001b[0m       0.0000        3.1446        0.1476\n",
      "    106        3.1716       0.0000        \u001b[35m3.1262\u001b[0m     +  0.1277\n",
      "    107        3.1718       0.0000        3.1305        0.1277\n",
      "    108        \u001b[36m3.1359\u001b[0m       0.0000        3.1438        0.1297\n",
      "    109        3.1532       0.0000        3.1318        0.1316\n",
      "    110        3.1570       0.0000        3.1496        0.1656\n",
      "    111        3.1830       0.0000        3.1456        0.1247\n",
      "    112        3.1681       0.0000        3.1385        0.1237\n",
      "    113        3.1725       0.0000        3.1401        0.1307\n",
      "    114        3.1463       0.0000        3.1344        0.1247\n",
      "    115        3.1662       0.0000        3.1364        0.1267\n",
      "    116        3.1360       0.0000        3.1346        0.1247\n",
      "    117        3.1370       0.0000        3.1330        0.1237\n",
      "    118        3.1598       0.0000        3.1378        0.1237\n",
      "    119        3.1571       0.0000        3.1288        0.1257\n",
      "    120        3.1749       0.0000        \u001b[35m3.1110\u001b[0m     +  0.1227\n",
      "    121        3.1572       0.0000        3.1329        0.1297\n",
      "    122        3.1585       0.0000        3.1351        0.1237\n",
      "    123        3.1413       0.0000        3.1385        0.1227\n",
      "    124        3.1644       0.0000        3.1255        0.1247\n",
      "    125        3.1685       0.0000        3.1325        0.1247\n",
      "    126        3.1513       0.0000        3.1408        0.1247\n",
      "    127        3.1611       0.0000        3.1326        0.1257\n",
      "    128        3.1498       0.0000        3.1307        0.1247\n",
      "    129        3.1568       0.0000        3.1441        0.1237\n",
      "    130        3.1701       0.0000        3.1334        0.1227\n",
      "    131        3.1708       0.0000        3.1410        0.1237\n",
      "    132        3.1438       0.0000        3.1285        0.1247\n",
      "    133        3.1532       0.0000        3.1334        0.1257\n",
      "    134        \u001b[36m3.1330\u001b[0m       0.0000        3.1503        0.1307\n",
      "    135        3.1512       0.0000        3.1299        0.1486\n",
      "    136        3.1438       0.0000        3.1292        0.1366\n",
      "    137        3.1919       0.0000        3.1424        0.1297\n",
      "    138        3.1798       0.0000        3.1349        0.1227\n",
      "    139        3.1647       0.0000        3.1270        0.1227\n",
      "    140        3.1600       0.0000        3.1310        0.1227\n",
      "    141        3.1965       0.0000        3.1483        0.1506\n",
      "    142        3.1901       0.0000        3.1351        0.1516\n",
      "    143        3.1340       0.0000        3.1371        0.1735\n",
      "    144        \u001b[36m3.1311\u001b[0m       0.0000        3.1310        0.1356\n",
      "    145        3.1442       0.0000        3.1361        0.1506\n",
      "    146        3.1462       0.0000        3.1353        0.1426\n",
      "    147        3.1431       0.0000        3.1306        0.1257\n",
      "    148        3.1561       0.0000        3.1336        0.1267\n",
      "    149        3.1493       0.0000        3.1344        0.1466\n",
      "    150        3.1458       0.0000        3.1448        0.1277\n",
      "    151        3.1416       0.0000        3.1368        0.1456\n",
      "    152        3.1461       0.0000        3.1357        0.1476\n",
      "    153        3.1655       0.0000        3.1344        0.1356\n",
      "    154        3.1524       0.0000        3.1316        0.1486\n",
      "    155        3.1500       0.0000        3.1286        0.1227\n",
      "    156        3.1773       0.0000        3.1269        0.1227\n",
      "    157        3.1534       0.0000        3.1318        0.1237\n",
      "    158        3.1602       0.0000        3.1248        0.1257\n",
      "    159        3.1458       0.0000        3.1352        0.1237\n",
      "    160        3.1630       0.0000        3.1229        0.1227\n",
      "    161        3.1460       0.0000        3.1378        0.1237\n",
      "    162        3.1926       0.0000        3.1468        0.1237\n",
      "    163        3.1550       0.0000        3.1346        0.1247\n",
      "    164        3.1655       0.0000        3.1336        0.1237\n",
      "    165        3.1314       0.0000        3.1316        0.1217\n",
      "    166        3.1528       0.0000        3.1391        0.1247\n",
      "    167        3.1784       0.0000        3.1382        0.1237\n",
      "    168        3.1381       0.0000        3.1260        0.1247\n",
      "    169        3.1322       0.0000        3.1277        0.1287\n",
      "    170        3.1418       0.0000        3.1398        0.1227\n",
      "    171        3.1366       0.0000        3.1377        0.1247\n",
      "    172        3.1410       0.0000        3.1259        0.1297\n",
      "    173        3.1681       0.0000        3.1383        0.1237\n",
      "    174        3.1503       0.0000        3.1280        0.1227\n",
      "    175        3.1569       0.0000        3.1368        0.1247\n",
      "    176        3.1559       0.0000        3.1276        0.1237\n",
      "    177        3.1362       0.0000        3.1286        0.1237\n",
      "    178        3.1599       0.0000        3.1450        0.1227\n",
      "    179        3.1505       0.0000        3.1470        0.1257\n",
      "    180        3.1314       0.0000        3.1510        0.1227\n",
      "    181        3.1444       0.0000        3.1258        0.1237\n",
      "    182        3.1690       0.0000        3.1443        0.1227\n",
      "    183        3.1728       0.0000        3.1412        0.1247\n",
      "    184        3.1690       0.0000        3.1218        0.1217\n",
      "    185        3.1514       0.0000        3.1263        0.1227\n",
      "    186        3.1461       0.0000        3.1270        0.1326\n",
      "    187        3.1748       0.0000        3.1464        0.1546\n",
      "    188        3.1536       0.0000        3.1414        0.1366\n",
      "    189        3.1424       0.0000        3.1362        0.1227\n",
      "    190        3.1454       0.0000        3.1363        0.1267\n",
      "    191        3.1470       0.0000        3.1310        0.1247\n",
      "    192        3.1632       0.0000        3.1452        0.1237\n",
      "    193        3.1558       0.0000        3.1395        0.1237\n",
      "    194        \u001b[36m3.1078\u001b[0m       0.0000        3.1370        0.1666\n",
      "    195        3.1633       0.0000        3.1349        0.1307\n",
      "    196        3.1609       0.0000        3.1386        0.1237\n",
      "    197        3.1607       0.0000        3.1371        0.1237\n",
      "    198        3.1695       0.0000        3.1319        0.1237\n",
      "    199        3.1267       0.0000        3.1251        0.1217\n",
      "    200        3.1471       0.0000        3.1303        0.1227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ArcFaceNet(\n",
       "    (net): MyNet(\n",
       "      (norm): L2N()\n",
       "      (fc1): Linear(in_features=39, out_features=32, bias=True)\n",
       "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): PReLU(num_parameters=32)\n",
       "      (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): PReLU(num_parameters=16)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train_preprocessed, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-nepal",
   "metadata": {},
   "source": [
    "### Train SVM on new features\n",
    "\n",
    "We can use linear kernel as two classes already separated on the hypersphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "popular-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = net.forward(X_train_preprocessed)\n",
    "clf = SVC(kernel='linear', class_weight='balanced', C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fiscal-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-while",
   "metadata": {},
   "source": [
    "### Calculate matthews coefficient on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "detailed-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_features = net.forward(X_test_preprocessed)\n",
    "# y_pred = clf.predict(X_test_features)\n",
    "# print(\"matthews test \", matthews_corrcoef(Y_test, y_pred))\n",
    "# print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accredited-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews train  0.49966470531820584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84      2639\n",
      "           1       0.56      0.75      0.64       952\n",
      "\n",
      "    accuracy                           0.78      3591\n",
      "   macro avg       0.73      0.77      0.74      3591\n",
      "weighted avg       0.81      0.78      0.79      3591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_features = net.forward(X_train_preprocessed)\n",
    "y_pred_train = clf.predict(X_train_features)\n",
    "print(\"matthews train \", matthews_corrcoef(Y_train, y_pred_train))\n",
    "print(classification_report(Y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-setting",
   "metadata": {},
   "source": [
    "### Get results on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regulated-archives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senior</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Internet</th>\n",
       "      <th>Security</th>\n",
       "      <th>Backup</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Support</th>\n",
       "      <th>TV</th>\n",
       "      <th>Movies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>EBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>58</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>99.15</td>\n",
       "      <td>5720.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Senior Married Dependents  Tenure     Internet Security Backup  \\\n",
       "Index                                                                  \n",
       "0         No      No         No      58  Fiber optic      Yes    Yes   \n",
       "\n",
       "      Insurance Support   TV Movies  Contract EBilling  \\\n",
       "Index                                                    \n",
       "0            No      No  Yes    Yes  One year       No   \n",
       "\n",
       "                   PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "Index                                                           \n",
       "0      Bank transfer (automatic)           99.15       5720.95  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('test.csv', index_col=0)\n",
    "data_test.TotalCharges = data_test.TotalCharges.replace(' ', 0).astype(float)\n",
    "data_test = data_test.drop(['Gender', 'Phone', 'MultiplePhones'], axis=1)\n",
    "data_test = data_test.replace({'Senior': {1: 'Yes', 0: 'No'}})\n",
    "data_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-island",
   "metadata": {},
   "source": [
    "### Preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vocal-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = preprocessor.transform(data_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-morocco",
   "metadata": {},
   "source": [
    "### Save answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sudden-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = net.forward(X_test_preprocessed)\n",
    "y_test_pred = clf.predict(X_test_features) == True\n",
    "answer = pd.DataFrame(data=y_test_pred,\n",
    "                      columns=['Churn'])\n",
    "answer.index.name = 'Index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "funded-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('./answer14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "intended-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('answer14.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brazilian-lodging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "False    1573\n",
       "True      822\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-mouth",
   "metadata": {},
   "source": [
    "### Смотрим соотношение true к false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "miniature-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5225683407501589"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.value_counts()[1] / data2.value_counts()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
